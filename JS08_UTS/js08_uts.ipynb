{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deteksi Emosi Pengguna Twitter\n",
    "\n",
    "Deteksi emosi merupakan salah satu permasalahan yang dihadapi pada ***Natural Language Processing*** (NLP). Alasanya diantaranya adalah kurangnya dataset berlabel untuk mengklasifikasikan emosi berdasarkan data twitter. Selain itu, sifat dari data twitter yang dapat memiliki banyak label emosi (***multi-class***). Manusia memiliki berbagai emosi dan sulit untuk mengumpulkan data yang cukup untuk setiap emosi. Oleh karena itu, masalah ketidakseimbangan kelas akan muncul (***class imbalance***). Pada Ujian Tengah Semester (UTS) kali ini, Anda telah disediakan dataset teks twitter yang sudah memiliki label untuk beberapa kelas emosi. Tugas utama Anda adalah membuat model yang mumpuni untuk kebutuhan klasifikasi emosi berdasarkan teks.\n",
    "\n",
    "### Informasi Data\n",
    "\n",
    "Dataset yang akan digunakan adalah ****tweet_emotion.csv***. Berikut merupakan informasi tentang dataset yang dapat membantu Anda.\n",
    "\n",
    "- Total data: 40000 data\n",
    "- Label emosi: anger, boredom, empty, enthusiasm, fun, happiness, hate, love, neutral, relief, sadness, surprise, worry\n",
    "- Jumlah data untuk setiap label tidak sama (***class imbalance***)\n",
    "- Terdapat 3 kolom = 'tweet_id', 'sentiment', 'content'\n",
    "\n",
    "### Penilaian UTS\n",
    "\n",
    "UTS akan dinilai berdasaarkan 4 proses yang akan Anda lakukan, yaitu pra pengolahan data, ektraksi fitur, pembuatan model machine learning, dan evaluasi.\n",
    "\n",
    "#### Pra Pengolahan Data\n",
    "\n",
    "> **Perhatian**\n",
    "> \n",
    "> Sebelum Anda melakukan sesuatu terhadap data Anda, pastikan data yang Anda miliki sudah \"baik\", bebas dari data yang hilang, menggunakan tipe data yang sesuai, dan sebagainya.\n",
    ">\n",
    "\n",
    "Data tweeter yang ada dapatkan merupakan sebuah data mentah, maka beberapa hal dapat Anda lakukan (namun tidak terbatas pada) yaitu,\n",
    "\n",
    "1. Case Folding\n",
    "2. Tokenizing\n",
    "3. Filtering\n",
    "4. Stemming\n",
    "\n",
    "\n",
    "*CATATAN: PADA DATA TWITTER TERDAPAT *MENTION* (@something) YANG ANDA HARUS TANGANI SEBELUM MASUK KE TAHAP EKSTRAKSI FITUR*\n",
    "\n",
    "#### Ekstrasi Fitur\n",
    "\n",
    "Anda dapat menggunakan beberapa metode, diantaranya\n",
    "\n",
    "1. Bag of Words (Count / TF-IDF)\n",
    "2. N-gram\n",
    "3. dan sebagainya\n",
    "\n",
    "#### Pembuatan Model\n",
    "\n",
    "Anda dibebaskan dalam memilih algoritma klasifikasi. Anda dapat menggunakan algoritma yang telah diajarkan didalam kelas atau yang lain, namun dengan catatan. Berdasarkan asas akuntabilitas pada pengembangan model machine learning, Anda harus dapat menjelaskan bagaimana model Anda dapat menghasilkan nilai tertentu.\n",
    "\n",
    "#### Evaluasi\n",
    "\n",
    "Pada proses evaluasi, minimal Anda harus menggunakan metric akurasi. Akan tetapi Anda juga dapat menambahkan metric lain seperti Recall, Precision, F1-Score, detail Confussion Metric, ataupun Area Under Curve (AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lembar Pengerjaan\n",
    "Lembar pengerjaan dimulai dari cell dibawah ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fashf\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,HashingVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment                                            content\n",
       "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
       "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
       "4  1956968416     neutral  @dannycastillo We want to trade with someone w...\n",
       "5  1956968477       worry  Re-pinging @ghostridah14: why didn't you go to...\n",
       "6  1956968487     sadness  I should be sleep, but im not! thinking about ...\n",
       "7  1956968636       worry               Hmmm. http://www.djhero.com/ is down\n",
       "8  1956969035     sadness            @charviray Charlene my love. I miss you\n",
       "9  1956969172     sadness         @kelcouch I'm sorry  at least it's Friday?"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/tweet_emotions.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet_id   40000 non-null  int64 \n",
      " 1   sentiment  40000 non-null  object\n",
      " 2   content    40000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['tweet_id', 'sentiment', 'content']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment = np.where((df.sentiment == 'neutral') | (df.sentiment == 'empty') | (df.sentiment == 'boredom'), 'neutral', df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment = np.where((df.sentiment == 'fun') | (df.sentiment == 'enthusiasm'), 'fun', df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.sentiment != 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worry        8459\n",
       "happiness    5209\n",
       "sadness      5165\n",
       "love         3842\n",
       "fun          2535\n",
       "surprise     2187\n",
       "relief       1526\n",
       "hate         1323\n",
       "anger         110\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/tweets_clean.txt',sep='\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145353048817012736:</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "      <td>:: surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144279638024257536:</td>\n",
       "      <td>Como una expresión tan simple, una sola oració...</td>\n",
       "      <td>:: sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140499585285111809:</td>\n",
       "      <td>the moment when you get another follower and y...</td>\n",
       "      <td>:: joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145207578270507009:</td>\n",
       "      <td>Be the greatest dancer of your life! practice ...</td>\n",
       "      <td>:: joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139502146390470656:</td>\n",
       "      <td>eww.. my moms starting to make her annual rum ...</td>\n",
       "      <td>:: disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146042696899887106:</td>\n",
       "      <td>If ur heart hurts all the time for tht person ...</td>\n",
       "      <td>:: joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>145492569609084928:</td>\n",
       "      <td>I feel awful, and it's way too freaking early....</td>\n",
       "      <td>:: joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>145903955229151232:</td>\n",
       "      <td>So chuffed for safc fans! Bet me dar comes in ...</td>\n",
       "      <td>:: joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>142717613234069504:</td>\n",
       "      <td>Making art and viewing art are different at th...</td>\n",
       "      <td>:: fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>144183822873927680:</td>\n",
       "      <td>Soooo dooowwwn!! Move on, get some sleep... Me...</td>\n",
       "      <td>:: anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                                                  1  \\\n",
       "0  145353048817012736:  Thinks that @melbahughes had a great 50th birt...   \n",
       "1  144279638024257536:  Como una expresión tan simple, una sola oració...   \n",
       "2  140499585285111809:  the moment when you get another follower and y...   \n",
       "3  145207578270507009:  Be the greatest dancer of your life! practice ...   \n",
       "4  139502146390470656:  eww.. my moms starting to make her annual rum ...   \n",
       "5  146042696899887106:  If ur heart hurts all the time for tht person ...   \n",
       "6  145492569609084928:  I feel awful, and it's way too freaking early....   \n",
       "7  145903955229151232:  So chuffed for safc fans! Bet me dar comes in ...   \n",
       "8  142717613234069504:  Making art and viewing art are different at th...   \n",
       "9  144183822873927680:  Soooo dooowwwn!! Move on, get some sleep... Me...   \n",
       "\n",
       "             2  \n",
       "0  :: surprise  \n",
       "1   :: sadness  \n",
       "2       :: joy  \n",
       "3       :: joy  \n",
       "4   :: disgust  \n",
       "5       :: joy  \n",
       "6       :: joy  \n",
       "7       :: joy  \n",
       "8      :: fear  \n",
       "9     :: anger  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns=['tweet_id','content','sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sentiment = df2.sentiment.str.replace(':: ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         8240\n",
       "surprise    3849\n",
       "sadness     3830\n",
       "fear        2816\n",
       "anger       1555\n",
       "disgust      761\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Emotions to keep\n",
    "\n",
    "##### worry,happpy(happiness,joy),surprise,sadness,love,fear,anger,hate(disgust+hate),relief,fun(fun+enthusiasm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>fun</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1956969531</td>\n",
       "      <td>worry</td>\n",
       "      <td>Choked on her retainers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1956970047</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Ugh! I have to beat this stupid song to get to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id sentiment                                            content\n",
       "1   1956967666   sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2   1956967696   sadness                Funeral ceremony...gloomy friday...\n",
       "3   1956967789       fun               wants to hang out with friends SOON!\n",
       "5   1956968477     worry  Re-pinging @ghostridah14: why didn't you go to...\n",
       "6   1956968487   sadness  I should be sleep, but im not! thinking about ...\n",
       "7   1956968636     worry               Hmmm. http://www.djhero.com/ is down\n",
       "8   1956969035   sadness            @charviray Charlene my love. I miss you\n",
       "9   1956969172   sadness         @kelcouch I'm sorry  at least it's Friday?\n",
       "11  1956969531     worry                            Choked on her retainers\n",
       "12  1956970047   sadness  Ugh! I have to beat this stupid song to get to..."
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.append(df2)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sentiment = np.where((data.sentiment == 'disgust') |(data.sentiment == 'hate'),'hate',data.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[data.sentiment.isin(['sadness','worry','joy'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness    8995\n",
       "worry      8459\n",
       "joy        8240\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membersihkan Teks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hapus karakter yang tidak relevan selain alfanumerik dan spasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-519-8e58614b0d91>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['content']=data['content'].str.replace('[^A-Za-z0-9\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "data['content']=data['content'].str.replace('[^A-Za-z0-9\\s]+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hapus tautan dari teks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-520-a260812f61fd>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['content']=data['content'].str.replace('http\\S+|www.\\S+', '', case=False)\n"
     ]
    }
   ],
   "source": [
    "data['content']=data['content'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ubah semuanya menjadi huruf kecil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content']=data['content'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tetapkan Variabel Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=data.sentiment\n",
    "data = data.drop(['sentiment'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "target=le.fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data kedalam train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,target,stratify=target,test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Periksa apakah split membagi kelas secara seragam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-525-01f9992843c9>:1: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  itemfreq(y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0, 4944],\n",
       "       [   1, 5397],\n",
       "       [   2, 5075]], dtype=int64)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemfreq(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-526-07c65b4fa6f5>:1: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  itemfreq(y_test)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0, 3296],\n",
       "       [   1, 3598],\n",
       "       [   2, 3384]], dtype=int64)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemfreq(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "##### Tokenization dapat dilakukan dengan berbagai cara, yaitu **Bag of words, tf-idf, Glove, word2vec ,fasttext** etc. Sekarang lakukan penerapannya dan pengaruhnya terhadap akurasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Bag of Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Term Frequency Matrix:  (15416, 25747)\n"
     ]
    }
   ],
   "source": [
    "# Extract fitur\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train.content)\n",
    "X_test_counts =count_vect.transform(X_test.content)\n",
    "print('Shape of Term Frequency Matrix: ',X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Naive Bayess Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.26250243237984\n"
     ]
    }
   ],
   "source": [
    "# Training Naive Bayes (NB) menggunakan training data.\n",
    "clf = MultinomialNB().fit(X_train_counts,y_train)\n",
    "predicted = clf.predict(X_test_counts)\n",
    "nb_clf_accuracy = np.mean(predicted == y_test) * 100\n",
    "print(nb_clf_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Menggunakan Pipeline**\n",
    "   * tentukan fungsi untuk akurasi pencetakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_acc(model):\n",
    "    predicted = model.predict(X_test.content)\n",
    "    accuracy = np.mean(predicted == y_test) * 100\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.26250243237984\n"
     ]
    }
   ],
   "source": [
    "nb_clf = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "nb_clf = nb_clf.fit(X_train.content,y_train)\n",
    "print_acc(nb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **TF IDF transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.54251799961082\n"
     ]
    }
   ],
   "source": [
    "nb_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "nb_clf = nb_clf.fit(X_train.content,y_train)\n",
    "print_acc(nb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Hash Vectorizer**\n",
    "   * Naive Bayes membutuhkan input non-negatif. Oleh karena itu, tanda alternatif harus disetel ke false di Hashing Vectorizer untuk membuatnya bekerja dengan algoritma naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.76532399299475\n"
     ]
    }
   ],
   "source": [
    "nb_clf = Pipeline([('vect', HashingVectorizer(n_features=2500,alternate_sign=False)), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "nb_clf = nb_clf.fit(X_train.content,y_train)\n",
    "print_acc(nb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2430,  517,  349],\n",
       "       [ 551, 1989, 1058],\n",
       "       [ 434, 1278, 1672]], dtype=int64)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Hapus Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.23117338003503\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "nb_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words)), ('clf', MultinomialNB())])\n",
    "nb_clf = nb_clf.fit(X_train.content,y_train)\n",
    "print_acc(nb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.60848414088344\n"
     ]
    }
   ],
   "source": [
    "nb_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words)), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "nb_clf = nb_clf.fit(X_train.content,y_train)\n",
    "print_acc(nb_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Lemmatization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)])\n",
    "X_train.loc[:,'content'] = X_train['content'].apply(lemmatize_text)\n",
    "X_test.loc[:,'content'] = X_test['content'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.41389375364857\n"
     ]
    }
   ],
   "source": [
    "nb_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words)), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "nb_clf = nb_clf.fit(X_train.content,y_train)\n",
    "print_acc(nb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c486722cb089da2a9d16a30b66cddd93aee8f7b05b83f2db7e9bc87c21ba6eae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
